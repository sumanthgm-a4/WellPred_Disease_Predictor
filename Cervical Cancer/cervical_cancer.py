# -*- coding: utf-8 -*-
"""Cervical Cancer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-yE3bGlyAx4ANAVb0undv7i9UH8or0iq

# **Preprocessing**
"""

!pip install imblearn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

data = pd.read_csv("cervical-cancer.csv")

data.head(5)

data.columns

data.replace(to_replace = '?', value = np.nan, inplace = True)

data.isna().sum()

data.drop(["STDs: Time since first diagnosis", "STDs: Time since last diagnosis"], axis = 1, inplace = True)

data.columns

plt.figure(figsize = (20, 7))
sns.heatmap(data.isnull(), yticklabels = False, cbar = False, cmap = "viridis")

plt.figure(figsize = (20, 7))
sns.countplot(x = "Biopsy", data = data)

data.info()

data = data.apply(pd.to_numeric)
data.info()

from sklearn.impute import SimpleImputer

mode_imputer = SimpleImputer(missing_values=np.nan, strategy = "most_frequent")
mean_imputer = SimpleImputer(missing_values=np.nan, strategy = "mean")

data["Num of pregnancies"] = mode_imputer.fit_transform(data[["Num of pregnancies"]])

data["First sexual intercourse"] = mean_imputer.fit_transform(data[["First sexual intercourse"]])

data["Number of sexual partners"] = mode_imputer.fit_transform(data[["Number of sexual partners"]])

data["Smokes"] = mode_imputer.fit_transform(data[["Smokes"]])

data["Smokes (years)"] = mean_imputer.fit_transform(data[["Smokes (years)"]])

data["Smokes (packs/year)"] = mean_imputer.fit_transform(data[["Smokes (packs/year)"]])

data["Hormonal Contraceptives"] = mode_imputer.fit_transform(data[["Hormonal Contraceptives"]])

data["Hormonal Contraceptives (years)"] = mean_imputer.fit_transform(data[["Hormonal Contraceptives (years)"]])

data["IUD"] = mode_imputer.fit_transform(data[["IUD"]])

data["IUD (years)"] = mean_imputer.fit_transform(data[["IUD (years)"]])

data["STDs"] = mode_imputer.fit_transform(data[["STDs"]])

data["STDs (number)"] = mode_imputer.fit_transform(data[["STDs (number)"]])

data["STDs:condylomatosis"] = mode_imputer.fit_transform(data[["STDs:condylomatosis"]])
data["STDs:cervical condylomatosis"] = mode_imputer.fit_transform(data[["STDs:cervical condylomatosis"]])
data["STDs:vaginal condylomatosis"] = mode_imputer.fit_transform(data[["STDs:vaginal condylomatosis"]])
data["STDs:vulvo-perineal condylomatosis"] = mode_imputer.fit_transform(data[["STDs:vulvo-perineal condylomatosis"]])

data["STDs:syphilis"] = mode_imputer.fit_transform(data[["STDs:syphilis"]])
data["STDs:pelvic inflammatory disease"] = mode_imputer.fit_transform(data[["STDs:pelvic inflammatory disease"]])
data["STDs:molluscum contagiosum"] = mode_imputer.fit_transform(data[["STDs:molluscum contagiosum"]])
data["STDs:HIV"] = mode_imputer.fit_transform(data[["STDs:HIV"]])
data["STDs:AIDS"] = mode_imputer.fit_transform(data[["STDs:AIDS"]])
data["STDs:genital herpes"] = mode_imputer.fit_transform(data[["STDs:genital herpes"]])
data["STDs:Hepatitis B"] = mode_imputer.fit_transform(data[["STDs:Hepatitis B"]])
data["STDs:HPV"] = mode_imputer.fit_transform(data[["STDs:HPV"]])

data.isna().sum()

"""# **Splitting the data**"""

target_df = data['Biopsy']
input_df = data.drop(['Biopsy'], axis=1)

X = np.array(input_df).astype('float32')
y = np.array(target_df).astype('float32')

y = y.reshape(-1,1)

print("Before oversampling, counts of label '0': {}".format(sum(y == 0)))
print("Before oversampling, counts of label '1': {}".format(sum(y == 1)))

#Oversampling using SMOTE

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state = 2)
X_new, y_new = smote.fit_resample(X, y.ravel())

print("After oversampling, counts of label '0': {}".format(sum(y_new == 0)))
print("After oversampling, counts of label '1': {}".format(sum(y_new == 1)))

# SPLITTING DATA INTO TRAIN AND TEST DATASETS
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.25)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)

"""# **XG Boost Model (works best)**"""

import xgboost as xgb

xgb_classifier = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 50, n_estimators = 100)
xgb_classifier.fit(X_train, y_train)

result_train = xgb_classifier.score(X_train, y_train)

result_train

y_pred = xgb_classifier.predict(X_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

cm = confusion_matrix(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)
print(classification_report(y_test, y_pred))
print()
print(cm)
print()
print(acc)

#Predicting a single result

xgb_classifier.predict(scaler.transform([[33,3.0,19.0,3.0,0.0,0.0,0.0,1.0,0.16,1.0,3.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,1,0,1,0,1,1,1,1,0]]))

"""# **Exporting the preprocessed dataset, scaler and the model**"""

import joblib

joblib.dump(value = [data, scaler, xgb_classifier, X_new, y_new], filename = "/content/cerv_canc_models.pkl")

